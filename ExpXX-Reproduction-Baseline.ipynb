{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reproduction - Baseline\n",
    "\n",
    "> Chung, J.S., Huh, J., Mun, S., Lee, M., Heo, H.S., Choe, S., Ham, C., Jung, S., Lee, B.-J., Han, I., 2020. In defence of metric learning for speaker recognition. arXiv Prepr. arXiv2003.11982.\n",
    "> 由官方提供"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 建模\n",
    "\n",
    "### 数据准备\n",
    "\n",
    "####  数据读取\n",
    "\n",
    "- 输入波形的帧长度：训练过程 200 帧，评估过程 300 帧，每帧 160 个采样点，16 kHz 采样率。\n",
    "- 训练的批量大小：200\n",
    "- 每个 epoch 中的单个说话人的最大段数量：100\n",
    "- 数据读取的多线程数量：5\n",
    "\n",
    "#### 训练数据和测试数据\n",
    "\n",
    "- 训练集列表：\"/workspace/rwang/voxceleb/train_list.txt\"\n",
    "- 测试集列表：\"/workspace/rwang/VoxSRC2020/data/verif/trials.txt\"\n",
    "- 训练集所在的根目录：\"/workspace/rwang/voxceleb/voxceleb2/\"\n",
    "- 测试集所在的根目录：\"/workspace/rwang/voxceleb/\"\n",
    "\n",
    "### 模型准备\n",
    "\n",
    "#### 模型介绍\n",
    "\n",
    "- 输入：40 维度梅尔滤波器组\n",
    "- 模型结构：ResNet34L\n",
    "- 编码器/池化层：Self-Attention Pooling (SAP)\n",
    "- 最后全链接层的嵌入大小：512\n",
    "\n",
    "#### 读取与保存的路径\n",
    "\n",
    "- 初始化模型，适用于预训练模型的载入：\"\"\n",
    "- 模型和日志的保存路径：\"\"\n",
    "\n",
    "### 训练与测试\n",
    "\n",
    "#### 训练参数\n",
    "\n",
    "- 评估间隔的 epoch 数量：10\n",
    "- epoch 数量：500\n",
    "- 损失函数：AMSoftmax\n",
    "- 优化器：Adam\n",
    "\n",
    "### 损失函数相关参数\n",
    "\n",
    "- 困难负样本挖掘概率 (PairwiseLoss - triplet/contrastive)：0.5\n",
    "- 每批困难负样本等级 (PairwiseLoss - triplet/contrastive)：10\n",
    "- 损失的间隔 (AMSoftmax, AAMsoftmax, PairwiseLoss)：0.3\n",
    "- 损失的尺度 (AMSoftmax, AAMsoftmax)：30\n",
    "- 说话人数量 (SoftmaxLoss, AMSoftmax, AAMsoftmax)：5994\n",
    "- 其它损失函数：AngleProtoLoss, GE2ELoss, ProtoLoss\n",
    "\n",
    "#### 学习率\n",
    "\n",
    "- 初始的学习率：0.001\n",
    "- 每次评估间隔衰减率：0.95\n",
    "\n",
    "#### 测试许可\n",
    "\n",
    "- 是否仅评估：False/True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 数据准备\n",
    "\n",
    "####  数据读取\n",
    "\n",
    "- 输入波形的帧长度：训练过程 200 帧，评估过程 300 帧，每帧 160 个采样点，16 kHz 采样率。\n",
    "- 训练的批量大小：200\n",
    "- 每个 epoch 中的单个说话人的最大段数量：100\n",
    "- 数据读取的多线程数量：5\n",
    "\n",
    "#### 训练数据和测试数据\n",
    "\n",
    "- 训练集列表：\"/workspace/rwang/voxceleb/train_list.txt\"\n",
    "- 测试集列表：\"/workspace/rwang/VoxSRC2020/data/verif/trials.txt\"\n",
    "- 训练集所在的根目录：\"/workspace/rwang/voxceleb/voxceleb2/\"\n",
    "- 测试集所在的根目录：\"/workspace/rwang/voxceleb/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from base import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainlst = \"/workspace/rwang/competition/voxsrc2020/train_part.txt\"\n",
    "testlst = \"/workspace/rwang/VoxSRC2020/data/verif/trials.txt\"\n",
    "traindir = \"/workspace/rwang/voxceleb/voxceleb2/\"\n",
    "testdir = \"/workspace/rwang/voxceleb/\"\n",
    "maptrain5994 = \"/workspace/rwang/competition/voxsrc2020/maptrain5994.txt\"\n",
    "\n",
    "batch_size = 512\n",
    "num_worker = 8\n",
    "max_utt_per_spk = 20\n",
    "L = 32240\n",
    "num_worker = 6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "trainloader = load_train(trainlst, traindir, maptrain5994, L=L, batch_size=batch_size, num_worker=num_worker, max_utt_per_spk=max_utt_per_spk)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "trials_loader = load_trial(testlst, testdir, batch_size=batch_size, num_worker=num_worker)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型准备\n",
    "\n",
    "#### 模型介绍\n",
    "\n",
    "- 输入：40 维度梅尔滤波器组\n",
    "- 模型结构：ResNet34L\n",
    "- 编码器/池化层：Self-Attention Pooling (SAP)\n",
    "- 最后全链接层的嵌入大小：512\n",
    "\n",
    "#### 读取与保存的路径\n",
    "\n",
    "- 初始化模型，适用于预训练模型的载入：\"\"\n",
    "- 模型和日志的保存路径：\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_mel = 40\n",
    "n_out = 512"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 训练与测试\n",
    "\n",
    "#### 训练参数\n",
    "\n",
    "- 评估间隔的 epoch 数量：10\n",
    "- epoch 数量：500\n",
    "- 损失函数：AMSoftmax\n",
    "- 优化器：Adam\n",
    "\n",
    "### 损失函数相关参数\n",
    "\n",
    "- 损失的间隔 (AMSoftmax, AAMsoftmax, PairwiseLoss)：0.3\n",
    "- 损失的尺度 (AMSoftmax, AAMsoftmax)：30\n",
    "- 说话人数量 (SoftmaxLoss, AMSoftmax, AAMsoftmax)：5994\n",
    "\n",
    "#### 学习率\n",
    "\n",
    "- 初始的学习率：0.001\n",
    "- 每次评估间隔衰减率：0.95"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_interval = 20\n",
    "num_epoch = 500\n",
    "margin = 0.2\n",
    "scale = 30\n",
    "num_speaker = 5994\n",
    "lr = 0.001\n",
    "gamma = 0.95\n",
    "log_dir = \"/workspace/rwang/competition/voxsrc2020/logs/exp-24\"\n",
    "device = \"cuda:1\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "eval_L = 48240\n",
    "mode = \"norm2\"\n",
    "num_eval = 10\n",
    "eval_batch_size = 30\n",
    "embed_norm = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 模型训练"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Embedding size is 512, encoder SAP.\n",
      "Initialized AMSoftmax margin = 0.200 scale = 30.000\n"
     ]
    }
   ],
   "source": [
    "net = ResNetSE34L(nOut=n_out)\n",
    "top = AMSoftmax(in_feats=n_out, n_classes=num_speaker, m=margin, s=scale)\n",
    "snet = SpeakerNet(device=device, log_dir=log_dir, eval_interval=eval_interval, lr=lr, gamma=gamma, top=top, net=net)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```cmd\n",
    "python ./trainSpeakerNet.py --model ResNetSE34L --encoder SAP --trainfunc amsoftmax --save_path data/exp1 --nSpeakers 5994 --batch_size 200 --scale 30 --margin 0.3 --train_list /workspace/rwang/voxceleb/train_list.txt --test_list /workspace/rwang/voxceleb/test_list.txt --train_path /workspace/rwang/voxceleb/voxceleb2 --test_path /workspace/rwang/voxceleb/voxceleb1\n",
    "```\n",
    "- （官方）训练速率：800 样本/秒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      " 30%|███       | 1417/4673 [03:13<07:26,  7.30it/s]"
     ]
    }
   ],
   "source": [
    "eer, thresh, all_scores, all_labels, all_trials, trials_feat = snet.evaluate(trials_loader, 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "snet.train(trainloader, trials_loader, num_epoch=num_epoch, step_num=11, \n",
    "           mode=mode, eval_L=eval_L, num_eval=num_eval, eval_batch_size=eval_batch_size, \n",
    "           embed_norm=embed_norm)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.8"
  },
  "toc-autonumbering": true,
  "toc-showcode": true,
  "toc-showmarkdowntxt": false
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
